import tensorflow as tf
from keras import backend as K
from keras.layers import Dense,Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import os
import cv2

sess=tf.Session()

K.set_session(sess)
#mnist=input_data.read_data_sets('MNIST_data',one_hot=True)

hight=100
width=50
channel=1
pic_num=40000
imgs=tf.placeholder(tf.float32,shape=(None,hight,width,channel))
labels=tf.placeholder(tf.float32,shape=(None,10))

conv1=Conv2D(6,[3,3],activation='relu')(imgs)
maxpool1=MaxPooling2D(pool_size=3, strides=2)(conv1)
conv2=Conv2D(6,[3,3],activation='relu')(maxpool1)
conv3=Conv2D(16,[3,3],activation='relu')(conv2)
conv4=Conv2D(1,[1,1],activation='relu')(conv3)
print(conv4.shape)
flat=tf.reshape(conv4,[-1,44*19])
fc1=Dense(100)(flat)
fc2=Dense(10)(fc1)
preds=tf.nn.softmax(fc2)

cross_entropy=tf.reduce_mean(-tf.reduce_sum(labels*tf.log(preds+1e-7)))
train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
#correct_prediction = tf.equal(tf.argmax(preds,1), tf.argmax(labels,1))
#accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
'''
x=mnist.train.images[:6000]
x=np.reshape(x,[-1,28,28,1])
y=mnist.train.labels[:6000]
'''
filename=[]
x=np.zeros([pic_num,100,50,1])
y=np.zeros([pic_num,10])
for k in range(10):
    filename.append(os.listdir('train/'+str(k)))
for j in range(pic_num):
    n=np.random.randint(0,10)
    n_pic=np.random.randint(0,len(filename[n]))
    name=filename[n][n_pic]
    img=cv2.imread('train/'+str(n)+'/'+filename[n][n_pic])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) / 255.
    #img= np.swapaxes(img,1,2)
    img=cv2.resize(img,(width,hight))
    x[j,:,:,0]=img
    y[j,n]=1
x=x.astype(np.float32)
y=y.astype(np.float64)

BATCH_num=64
sess.run(tf.global_variables_initializer())
saver=tf.train.Saver()
predict=tf.arg_max(preds,1)
for i in range(100):
    for j in range(int(35000/64.)):
        sess.run(train_step,feed_dict={imgs:x[BATCH_num*j:BATCH_num*(j+1)],labels:y[BATCH_num*j:BATCH_num*(j+1)]})
        #if j%100==0:
        #    print(sess.run(cross_entropy,feed_dict={imgs:x[BATCH_num*j:BATCH_num*(j+1)],labels:y[BATCH_num*j:BATCH_num*j+1]}))
    results = []
    for k in range(int(5000 / 64.)):
        k=k+int(35000/64)
        results.extend(np.argmax(y[BATCH_num*k:BATCH_num*(k+1)], axis=1) ==sess.run(predict, feed_dict={imgs:x[BATCH_num*k:BATCH_num*(k+1)]}))
        #test_acc = accuracy.eval(feed_dict={imgs:x[BATCH_num*k:BATCH_num*(k+1)],labels:y[BATCH_num*k:BATCH_num*(k+1)]},session=sess)
    print('Epoch: %d, Test Accuracy: %f' % (i + 1, np.mean(results)))

        # rms.extend(np.sq
    saver.save(sess,'./output/save.ckpt',global_step=i)


